{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecafdc02",
   "metadata": {},
   "source": [
    "# Tarea 3. Transformer con llamadas a funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f77589",
   "metadata": {},
   "source": [
    "Una evolución interesante de los primeros LLMs fue la incorporación de llamadas a funciones para superar las limitaciones en cálculos concretos de los modelos de lenguajes. <br>\n",
    "Para esta tarea final utilizamos los ficheros: fechas2_train_function.en.csv y fechas2_train_function.es.csv en la que se añade al final del texto a reconocer un separador ‘|’ y un código de Python para llamar al sistema y pedir que ejecute esa función <br>\n",
    "Prepare un sistema como el de la tarea 1 que entrene combinando las listas de los dos idiomas para que sea bilingüe dentro del contexto simplificado de esta tarea.\n",
    "En test esta vez en lugar de medir la tasa de error WER lo que haremos es ejecutar el código dentro de la sección separada y comparar la fecha que genera con la de referencia de la tabla: <br>\n",
    "fechas2_test_function.csv <br>\n",
    "y evaluaremos la tasa de error. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f09a94",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bce6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch, torchaudio, glob\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from Trabajo_Utils import NoiseAug, RIRAug, identity, wer\n",
    "from Trabajo_Model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc8f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "SEQ_LEN = 20\n",
    "NB_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def seed_everything(seed):      \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f9dfc",
   "metadata": {},
   "source": [
    "### Data Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5914d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"FluidInference/musan\", split=\"train\")\n",
    "\n",
    "# if not os.path.exists(\"musan_small\"):\n",
    "#     os.makedirs(\"musan_small\", exist_ok=True)\n",
    "#     for i, example in enumerate(dataset):\n",
    "#         audio = example[\"audio\"][\"array\"]\n",
    "#         sr = example[\"audio\"][\"sampling_rate\"]\n",
    "#         sf.write(f\"musan_small/file_{i}.wav\", audio, sr)\n",
    "        \n",
    "# url = 'https://openslr.elda.org/resources/28/rirs_noises.zip'\n",
    "\n",
    "# if not os.path.exists('RIRS_NOISES'):\n",
    "#     if not os.path.exists('rirs_noises.zip'):\n",
    "#         os.system('wget ' + url)\n",
    "#     os.system('unzip -q rirs_noises.zip')\n",
    "#     os.system('rm rirs_noises.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140a3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def relative_day(days_to_add, current_date='21/11/2025'):\n",
    "    date_format = \"%d/%m/%Y\"\n",
    "    current = datetime.strptime(current_date, date_format)\n",
    "    new_date = current + timedelta(days=int(days_to_add))\n",
    "    return new_date.strftime(date_format)\n",
    "\n",
    "def next_day(day_name, current_date='21/11/2025'):\n",
    "    date_format = \"%d/%m/%Y\"\n",
    "    current = datetime.strptime(current_date, date_format)\n",
    "    \n",
    "    # Map day names → ISO weekday codes\n",
    "    day_name = day_name.strip().lower()\n",
    "    day_map = {\n",
    "        \"monday\": 1,\n",
    "        \"tuesday\": 2,\n",
    "        \"wednesday\": 3,\n",
    "        \"thursday\": 4,\n",
    "        \"friday\": 5,\n",
    "        \"saturday\": 6,\n",
    "        \"sunday\": 7,\n",
    "    }\n",
    "    if day_name not in day_map:\n",
    "        raise ValueError(f\"Invalid day name: {day_name}\")\n",
    "    \n",
    "    target_code = day_map[day_name]\n",
    "    days_ahead = (target_code - current.isoweekday()) % 7\n",
    "    if days_ahead == 0:\n",
    "        days_ahead = 7 # always next occurrence\n",
    "        \n",
    "    new_date = current + timedelta(days=days_ahead)\n",
    "    return new_date.strftime(date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed79d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordTokenizer:\n",
    "    def __init__(self, csv_file):\n",
    "        self.word2index = {\n",
    "            '<pad>': 0,\n",
    "            '<sos>': 1,\n",
    "            '<eos>': 2,\n",
    "            '<unk>': 3\n",
    "        }\n",
    "        self.index2word = {\n",
    "            0: '<pad>',\n",
    "            1: '<sos>',\n",
    "            2: '<eos>',\n",
    "            3: '<unk>'\n",
    "        }\n",
    "\n",
    "        self.build_vocab(csv_file)\n",
    "\n",
    "    def build_vocab(self, csv_file):\n",
    "        with open(csv_file, newline='', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                text = row['txt'].lower()\n",
    "                for word in text.split():\n",
    "                    if word not in self.word2index:\n",
    "                        idx = len(self.word2index)\n",
    "                        self.word2index[word] = idx\n",
    "                        self.index2word[idx] = word\n",
    "\n",
    "    def encode(self, text, seq_len=-1):\n",
    "        tokens = ['<sos>'] + text.lower().split() + ['<eos>']\n",
    "        ids = [\n",
    "            self.word2index.get(w, self.word2index['<unk>'])\n",
    "            for w in tokens\n",
    "        ]\n",
    "\n",
    "        if seq_len > len(ids):\n",
    "            ids += [self.word2index['<pad>']] * (seq_len - len(ids))\n",
    "        else:\n",
    "            ids = ids[:seq_len]\n",
    "\n",
    "        return torch.tensor(ids)\n",
    "\n",
    "\n",
    "    def decode(self, ids):\n",
    "        if isinstance(ids, torch.Tensor):\n",
    "            ids = ids.tolist()\n",
    "\n",
    "        words = [self.index2word.get(i, '<unk>') for i in ids]\n",
    "        text = ' '.join(words)\n",
    "        text = text.replace('<sos>', '').replace('<eos>', '').replace('<pad>', '')\n",
    "        return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6ea91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, audio_len=4*16000, seq_len=SEQ_LEN):\n",
    "        self.audio_len = audio_len\n",
    "        self.seq_len = seq_len\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        with open(csv_file, encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            self.data = [(r['wav'], r['txt']) for r in reader]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav, txt = self.data[idx]\n",
    "        x, _ = torchaudio.load(wav)\n",
    "\n",
    "        if x.shape[1] < self.audio_len:\n",
    "            x = torch.nn.functional.pad(x, (0, self.audio_len - x.shape[1]))\n",
    "        else:\n",
    "            x = x[:, :self.audio_len]\n",
    "\n",
    "        x = x[0]\n",
    "        y = self.tokenizer.encode(txt, self.seq_len)\n",
    "        return x, y\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, audio_len=4*16000, seq_len=SEQ_LEN):\n",
    "        self.audio_len = audio_len\n",
    "        self.seq_len = seq_len\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        with open(csv_file, encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            self.data = [(row['wav'], row['txt']) for row in reader]\n",
    "\n",
    "        print(len(self.data))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav_path, text = self.data[idx]\n",
    "\n",
    "        x, fs = torchaudio.load(wav_path)\n",
    "        if x.shape[1] < self.audio_len:\n",
    "            x = torch.nn.functional.pad(\n",
    "                x, (0, self.audio_len - x.shape[1]), value=0\n",
    "            )\n",
    "        else:\n",
    "            x = x[:, :self.audio_len]\n",
    "\n",
    "        x = x[0]\n",
    "        y = self.tokenizer.encode(text, self.seq_len)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d400b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "tokenizer = WordTokenizer('fechas2/fechas2_train_function.es.csv')\n",
    "tokenizer.build_vocab('fechas2/fechas2_train_function.en.csv')\n",
    "\n",
    "train_es = TrainDataset(\n",
    "    'fechas2/fechas2_train_function.es.csv',\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "train_en = TrainDataset(\n",
    "    'fechas2/fechas2_train_function.en.csv',\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "trainset = torch.utils.data.ConcatDataset([train_es, train_en])\n",
    "\n",
    "testset = TestDataset(\n",
    "    'fechas2/fechas2_test_function.csv',\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa060d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word2index)\n",
    "\n",
    "model = AudioTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=256,\n",
    "    nb_layers=8,\n",
    "    d_ff=512,\n",
    "    n_heads=8,\n",
    "    d_head=32,\n",
    "    dropout=0.1,\n",
    "    seq_len=SEQ_LEN\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "pad_idx = tokenizer.word2index['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01627471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# BATCH_FACTOR = 3\n",
    "# MAX_BATCH = None\n",
    "# if device == 'cpu':\n",
    "#     MAX_BATCH = math.ceil(len(trainloader) / BATCH_FACTOR)\n",
    "\n",
    "# model.train()\n",
    "# for epoch in range(NB_EPOCHS):\n",
    "#     total_loss = 0\n",
    "\n",
    "#     for i, (x, y) in enumerate(trainloader):\n",
    "#         if MAX_BATCH is not None and i >= MAX_BATCH:\n",
    "#             break\n",
    "\n",
    "#         x = x.to(device)\n",
    "#         y = y.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = model.loss(x, y, pad_idx=pad_idx)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}/{NB_EPOCHS} - Loss: {total_loss/(i+1):.3f}\")\n",
    "\n",
    "# torch.save(model.state_dict(), \"model_function.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd925727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code(text): \n",
    "    if '|' not in text:\n",
    "        return None\n",
    "    _, code = text.split('|', 1) \n",
    "    return code.strip()\n",
    "\n",
    "def execute_code(code):\n",
    "    try:\n",
    "        return eval(code, { \"relative_day\": relative_day, \"next_day\": next_day })\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "924b3916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioTransformer(\n",
       "  (fe): AudioFeatures(\n",
       "    (fe): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (spec_aug): SpecAug()\n",
       "    (linear): Linear(in_features=80, out_features=256, bias=True)\n",
       "  )\n",
       "  (enc): Encoder(\n",
       "    (att): ModuleList(\n",
       "      (0-7): 8 x SelfAttention(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (q_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (ff): ModuleList(\n",
       "      (0-7): 8 x FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (emb): Embedding(60, 256)\n",
       "  (dec): Decoder(\n",
       "    (att): ModuleList(\n",
       "      (0-7): 8 x CausalSelfAttention(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (q_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (cross_att): ModuleList(\n",
       "      (0-7): 8 x CrossAttention(\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (q_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (ff): ModuleList(\n",
       "      (0-7): 8 x FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=60, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AudioTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=256,\n",
    "    nb_layers=8,\n",
    "    d_ff=512,\n",
    "    n_heads=8,\n",
    "    d_head=32,\n",
    "    dropout=0.1,\n",
    "    seq_len=SEQ_LEN\n",
    ")\n",
    "\n",
    "state = torch.load(\"model_function.pt\", map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98e1eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REF DATE : 23/11/2025\n",
      "HYP TEXT : the day after tomorrow thanks | relative_day(+2)\n",
      "PRED DATE: 23/11/2025\n",
      "----------------------------------------\n",
      "REF DATE : 23/11/2025\n",
      "HYP TEXT : please this coming thursday | next_day('thursday')\n",
      "PRED DATE: 27/11/2025\n",
      "----------------------------------------\n",
      "REF DATE : 23/11/2025\n",
      "HYP TEXT : por favor en un par de días | relative_day(+2)\n",
      "PRED DATE: 23/11/2025\n",
      "----------------------------------------\n",
      "REF DATE : 27/11/2025\n",
      "HYP TEXT : this thursday thank you | next_day('thursday')\n",
      "PRED DATE: 27/11/2025\n",
      "----------------------------------------\n",
      "REF DATE : 26/11/2025\n",
      "HYP TEXT : please next wednesday | next_day('wednesday')\n",
      "PRED DATE: 26/11/2025\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x, _ = testset[i]\n",
    "    wav, ref_date = testset.data[i]\n",
    "\n",
    "    hyp_ids = model.generate(x.unsqueeze(0), tokenizer)\n",
    "    hyp_text = tokenizer.decode(hyp_ids)\n",
    "\n",
    "    code = extract_code(hyp_text)\n",
    "    pred_date = execute_code(code) if code else None\n",
    "\n",
    "    print(\"REF DATE :\", ref_date)\n",
    "    print(\"HYP TEXT :\", hyp_text)\n",
    "    print(\"PRED DATE:\", pred_date)\n",
    "    print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8057ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_function(model, dataset, tokenizer, gen_mode = 'greedy'):\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        x, _ = dataset[i]\n",
    "        if gen_mode == 'greedy':\n",
    "            hyp_ids = model.generate(x.unsqueeze(0), tokenizer)\n",
    "        elif gen_mode == 'sampling':\n",
    "            hyp_ids = model.generate_sampling(x.unsqueeze(0), tokenizer)\n",
    "        elif gen_mode == 'topk':\n",
    "            hyp_ids = model.generate_topk(x.unsqueeze(0), tokenizer)\n",
    "        elif gen_mode == 'beam':\n",
    "            hyp_ids = model.generate_beam_search(x.unsqueeze(0), tokenizer\n",
    "                                                ,beam_size=5)\n",
    "        hyp = tokenizer.decode(hyp_ids)\n",
    "\n",
    "        code = extract_code(hyp)\n",
    "        if code is None:\n",
    "            continue\n",
    "\n",
    "        pred = execute_code(code)\n",
    "        ref = dataset.data[i][1]\n",
    "\n",
    "        if pred == ref:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90543747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Tarea 3: 0.951\n",
      "Accuracy Tarea 3 - sampling: 0.931\n",
      "Accuracy Tarea 3 - topk: 0.917\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model_function.pt\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "acc = evaluate_function(model, testset, tokenizer, gen_mode = 'greedy')\n",
    "print(f\"Accuracy Tarea 3: {acc:.3f}\")\n",
    "\n",
    "acc = evaluate_function(model, testset, tokenizer, gen_mode = 'sampling')\n",
    "print(f\"Accuracy Tarea 3 - sampling: {acc:.3f}\")\n",
    "\n",
    "acc = evaluate_function(model, testset, tokenizer, gen_mode = 'topk')\n",
    "print(f\"Accuracy Tarea 3 - topk: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c14aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Tarea 3 - beam: 0.954\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_function(model, testset, tokenizer, gen_mode = 'beam')\n",
    "print(f\"Accuracy Tarea 3 - beam: {acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
