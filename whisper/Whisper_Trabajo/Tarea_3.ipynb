{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecafdc02",
   "metadata": {},
   "source": [
    "# Tarea 3. Transformer con llamadas a funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f77589",
   "metadata": {},
   "source": [
    "Una evolución interesante de los primeros LLMs fue la incorporación de llamadas a funciones para superar las limitaciones en cálculos concretos de los modelos de lenguajes. <br>\n",
    "Para esta tarea final utilizamos los ficheros: fechas2_train_function.en.csv y fechas2_train_function.es.csv en la que se añade al final del texto a reconocer un separador ‘|’ y un código de Python para llamar al sistema y pedir que ejecute esa función <br>\n",
    "Prepare un sistema como el de la tarea 1 que entrene combinando las listas de los dos idiomas para que sea bilingüe dentro del contexto simplificado de esta tarea.\n",
    "En test esta vez en lugar de medir la tasa de error WER lo que haremos es ejecutar el código dentro de la sección separada y comparar la fecha que genera con la de referencia de la tabla: <br>\n",
    "fechas2_test_function.csv <br>\n",
    "y evaluaremos la tasa de error. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f09a94",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bce6237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giuseppe/.pyenv/versions/hlt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch, torchaudio\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import random\n",
    "import csv\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from Trabajo_Model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc8f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "SEQ_LEN = 20\n",
    "NB_EPOCHS = 4\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def seed_everything(seed):      \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f9dfc",
   "metadata": {},
   "source": [
    "### Data Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5914d850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/main/README.md (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 8556be14-b596-4e49-96bf-726cc9b04f5e)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/main/README.md\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/main/README.md (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: f126ca4c-05b1-4533-9309-e74b71bdadc8)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/main/README.md\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/main/README.md (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 4fd0719b-511c-4d25-a6a6-41b4e7adf9d0)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/main/README.md\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/main/README.md (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 024c9d78-57dd-4ce3-ad80-e7a489ddb45d)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/main/README.md\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/main/README.md (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 22161a75-b811-4204-9df0-6dde48bb28f9)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/main/README.md\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/main/README.md (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 26e5e1ce-9c1d-42d5-823c-f6f940fa9064)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/main/README.md\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 41228242-1f95-41c0-945e-d9cc7349b8c3)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 6a4ff982-9ac4-497d-ac14-c9dc3ebfa076)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 1cc1c216-3c26-4fe9-a304-420e1a731673)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 07b0f107-8fea-412f-bd22-8420d001a574)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 0105d8e9-331e-4832-a0c9-1ffcac118aec)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py (Caused by NameResolutionError(\"HTTPSConnection(host=\\'huggingface.co\\', port=443): Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: a07b058c-b1a5-4f12-b916-56ad8533750f)')' thrown while requesting HEAD https://huggingface.co/datasets/FluidInference/musan/resolve/3edcfdf89b56dbe6a395ff29f9c29489e03d1321/musan.py\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Using the latest cached version of the dataset since FluidInference/musan couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/giuseppe/.cache/huggingface/datasets/FluidInference___musan/default/0.0.0/3edcfdf89b56dbe6a395ff29f9c29489e03d1321 (last modified on Tue Jan  6 11:06:18 2026).\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"FluidInference/musan\", split=\"train\")\n",
    "\n",
    "if not os.path.exists(\"musan_small\"):\n",
    "    os.makedirs(\"musan_small\", exist_ok=True)\n",
    "    for i, example in enumerate(dataset):\n",
    "        audio = example[\"audio\"][\"array\"]\n",
    "        sr = example[\"audio\"][\"sampling_rate\"]\n",
    "        sf.write(f\"musan_small/file_{i}.wav\", audio, sr)\n",
    "        \n",
    "url = 'https://openslr.elda.org/resources/28/rirs_noises.zip'\n",
    "\n",
    "if not os.path.exists('RIRS_NOISES'):\n",
    "    if not os.path.exists('rirs_noises.zip'):\n",
    "        os.system('wget ' + url)\n",
    "    os.system('unzip -q rirs_noises.zip')\n",
    "    os.system('rm rirs_noises.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140a3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relative_day(days_to_add, current_date='21/11/2025'):\n",
    "    date_format = \"%d/%m/%Y\"\n",
    "    current = datetime.strptime(current_date, date_format)\n",
    "    new_date = current + timedelta(days=int(days_to_add))\n",
    "    return new_date.strftime(date_format)\n",
    "\n",
    "def next_day(day_name, current_date='21/11/2025'):\n",
    "    date_format = \"%d/%m/%Y\"\n",
    "    current = datetime.strptime(current_date, date_format)\n",
    "    \n",
    "    # Map day names → ISO weekday codes\n",
    "    day_name = day_name.strip().lower()\n",
    "    day_map = {\n",
    "        \"monday\": 1,\n",
    "        \"tuesday\": 2,\n",
    "        \"wednesday\": 3,\n",
    "        \"thursday\": 4,\n",
    "        \"friday\": 5,\n",
    "        \"saturday\": 6,\n",
    "        \"sunday\": 7,\n",
    "    }\n",
    "    if day_name not in day_map:\n",
    "        raise ValueError(f\"Invalid day name: {day_name}\")\n",
    "    \n",
    "    target_code = day_map[day_name]\n",
    "    days_ahead = (target_code - current.isoweekday()) % 7\n",
    "    if days_ahead == 0:\n",
    "        days_ahead = 7 # always next occurrence\n",
    "        \n",
    "    new_date = current + timedelta(days=days_ahead)\n",
    "    return new_date.strftime(date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed79d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordTokenizer:\n",
    "    def __init__(self, csv_file):\n",
    "        self.word2index = {\n",
    "            '<pad>': 0,\n",
    "            '<sos>': 1,\n",
    "            '<eos>': 2,\n",
    "            '<unk>': 3\n",
    "        }\n",
    "        self.index2word = {\n",
    "            0: '<pad>',\n",
    "            1: '<sos>',\n",
    "            2: '<eos>',\n",
    "            3: '<unk>'\n",
    "        }\n",
    "\n",
    "        self.build_vocab(csv_file)\n",
    "\n",
    "    def build_vocab(self, csv_file):\n",
    "        with open(csv_file, newline='', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                text = row['txt'].lower()\n",
    "                for word in text.split():\n",
    "                    if word not in self.word2index:\n",
    "                        idx = len(self.word2index)\n",
    "                        self.word2index[word] = idx\n",
    "                        self.index2word[idx] = word\n",
    "\n",
    "    def encode(self, text, seq_len=-1):\n",
    "        tokens = ['<sos>'] + text.lower().split() + ['<eos>']\n",
    "        ids = [\n",
    "            self.word2index.get(w, self.word2index['<unk>'])\n",
    "            for w in tokens\n",
    "        ]\n",
    "\n",
    "        if seq_len > len(ids):\n",
    "            ids += [self.word2index['<pad>']] * (seq_len - len(ids))\n",
    "        else:\n",
    "            ids = ids[:seq_len]\n",
    "\n",
    "        return torch.tensor(ids)\n",
    "\n",
    "\n",
    "    def decode(self, ids):\n",
    "        if isinstance(ids, torch.Tensor):\n",
    "            ids = ids.tolist()\n",
    "\n",
    "        words = [self.index2word.get(i, '<unk>') for i in ids]\n",
    "        text = ' '.join(words)\n",
    "        text = text.replace('<sos>', '').replace('<eos>', '').replace('<pad>', '')\n",
    "        return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6ea91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, audio_len=4*16000, seq_len=SEQ_LEN):\n",
    "        self.audio_len = audio_len\n",
    "        self.seq_len = seq_len\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        with open(csv_file, encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            self.data = [(r['wav'], r['txt']) for r in reader]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav, txt = self.data[idx]\n",
    "        x, _ = torchaudio.load(wav)\n",
    "\n",
    "        if x.shape[1] < self.audio_len:\n",
    "            x = torch.nn.functional.pad(x, (0, self.audio_len - x.shape[1]))\n",
    "        else:\n",
    "            x = x[:, :self.audio_len]\n",
    "\n",
    "        x = x[0]\n",
    "        y = self.tokenizer.encode(txt, self.seq_len)\n",
    "        return x, y\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, audio_len=4*16000, seq_len=SEQ_LEN):\n",
    "        self.audio_len = audio_len\n",
    "        self.seq_len = seq_len\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        with open(csv_file, encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            self.data = [(row['wav'], row['txt']) for row in reader]\n",
    "\n",
    "        print(len(self.data))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav_path, text = self.data[idx]\n",
    "\n",
    "        x, fs = torchaudio.load(wav_path)\n",
    "        if x.shape[1] < self.audio_len:\n",
    "            x = torch.nn.functional.pad(\n",
    "                x, (0, self.audio_len - x.shape[1]), value=0\n",
    "            )\n",
    "        else:\n",
    "            x = x[:, :self.audio_len]\n",
    "\n",
    "        x = x[0]\n",
    "        y = self.tokenizer.encode(text, self.seq_len)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d400b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "tokenizer = WordTokenizer('fechas2/fechas2_train_function.es.csv')\n",
    "tokenizer.build_vocab('fechas2/fechas2_train_function.en.csv')\n",
    "\n",
    "train_es = TrainDataset(\n",
    "    'fechas2/fechas2_train_function.es.csv',\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "train_en = TrainDataset(\n",
    "    'fechas2/fechas2_train_function.en.csv',\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "trainset = torch.utils.data.ConcatDataset([train_es, train_en])\n",
    "\n",
    "testset = TestDataset(\n",
    "    'fechas2/fechas2_test_function.csv',\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa060d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word2index)\n",
    "\n",
    "model = AudioTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=256,\n",
    "    nb_layers=8,\n",
    "    d_ff=512,\n",
    "    n_heads=8,\n",
    "    d_head=32,\n",
    "    dropout=0.1,\n",
    "    seq_len=SEQ_LEN\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "pad_idx = tokenizer.word2index['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01627471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 - Loss: 0.828\n",
      "Epoch 2/4 - Loss: 0.270\n",
      "Epoch 3/4 - Loss: 0.123\n",
      "Epoch 4/4 - Loss: 0.080\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "BATCH_FACTOR = 2\n",
    "MAX_BATCH = None\n",
    "if device == 'cpu':\n",
    "    MAX_BATCH = math.ceil(len(trainloader) / BATCH_FACTOR)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(NB_EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(trainloader):\n",
    "        if MAX_BATCH is not None and i >= MAX_BATCH:\n",
    "            break\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(x, y, pad_idx=pad_idx)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NB_EPOCHS} - Loss: {total_loss/(i+1):.3f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model_function.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd925727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code(text): \n",
    "    if '|' not in text:\n",
    "        return None\n",
    "    _, code = text.split('|', 1) \n",
    "    return code.strip()\n",
    "\n",
    "def execute_code(code):\n",
    "    try:\n",
    "        return eval(code, { \"relative_day\": relative_day, \"next_day\": next_day })\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "924b3916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioTransformer(\n",
       "  (fe): AudioFeatures(\n",
       "    (fe): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (spec_aug): SpecAug()\n",
       "    (linear): Linear(in_features=80, out_features=256, bias=True)\n",
       "  )\n",
       "  (enc): Encoder(\n",
       "    (att): ModuleList(\n",
       "      (0-7): 8 x SelfAttention(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (q_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (ff): ModuleList(\n",
       "      (0-7): 8 x FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (emb): Embedding(60, 256)\n",
       "  (dec): Decoder(\n",
       "    (att): ModuleList(\n",
       "      (0-7): 8 x CausalSelfAttention(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (q_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (cross_att): ModuleList(\n",
       "      (0-7): 8 x CrossAttention(\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (q_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (ff): ModuleList(\n",
       "      (0-7): 8 x FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=60, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AudioTransformer(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=256,\n",
    "    nb_layers=8,\n",
    "    d_ff=512,\n",
    "    n_heads=8,\n",
    "    d_head=32,\n",
    "    dropout=0.1,\n",
    "    seq_len=SEQ_LEN\n",
    ")\n",
    "\n",
    "state = torch.load(\"model_function.pt\", map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e1eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REF DATE : 23/11/2025\n",
      "HYP TEXT : the day after tomorrow thanks | relative_day(+2)\n",
      "PRED DATE: 23/11/2025\n",
      "----------------------------------------\n",
      "REF DATE : 23/11/2025\n",
      "HYP TEXT : please | relative_day(+2)\n",
      "PRED DATE: 23/11/2025\n",
      "----------------------------------------\n",
      "REF DATE : 23/11/2025\n",
      "HYP TEXT : por favor mañana | relative_day(+1)\n",
      "PRED DATE: 22/11/2025\n",
      "----------------------------------------\n",
      "REF DATE : 27/11/2025\n",
      "HYP TEXT : this thursday thank you | next_day('thursday')\n",
      "PRED DATE: 27/11/2025\n",
      "----------------------------------------\n",
      "REF DATE : 26/11/2025\n",
      "HYP TEXT : please next wednesday | next_day('wednesday')\n",
      "PRED DATE: 26/11/2025\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x, _ = testset[i]\n",
    "    wav, ref_date = testset.data[i]\n",
    "\n",
    "    hyp_ids = model.generate(x.unsqueeze(0), tokenizer)\n",
    "    hyp_text = tokenizer.decode(hyp_ids)\n",
    "\n",
    "    code = extract_code(hyp_text)\n",
    "    pred_date = execute_code(code) if code else None\n",
    "\n",
    "    print(\"REF DATE :\", ref_date)\n",
    "    print(\"HYP TEXT :\", hyp_text)\n",
    "    print(\"PRED DATE:\", pred_date)\n",
    "    print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8057ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_function(model, dataset, tokenizer, gen_mode = 'greedy'):\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        x, _ = dataset[i]\n",
    "        if gen_mode == 'greedy':\n",
    "            hyp_ids = model.generate(x.unsqueeze(0), tokenizer)\n",
    "        elif gen_mode == 'sampling':\n",
    "            hyp_ids = model.generate_sampling(x.unsqueeze(0), tokenizer)\n",
    "        elif gen_mode == 'topk':\n",
    "            hyp_ids = model.generate_topk(x.unsqueeze(0), tokenizer)\n",
    "        elif gen_mode == 'beam':\n",
    "            hyp_ids = model.generate_beam_search(x.unsqueeze(0), tokenizer, beam_size=5)\n",
    "        hyp = tokenizer.decode(hyp_ids)\n",
    "\n",
    "        code = extract_code(hyp)\n",
    "        if code is None:\n",
    "            continue\n",
    "\n",
    "        pred = execute_code(code)\n",
    "        ref = dataset.data[i][1]\n",
    "\n",
    "        if pred == ref:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90543747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Tarea 3: 0.767\n",
      "Accuracy Tarea 3 - sampling: 0.722\n",
      "Accuracy Tarea 3 - topk: 0.731\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model_function.pt\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "acc = evaluate_function(model, testset, tokenizer, gen_mode = 'greedy')\n",
    "print(f\"Accuracy Tarea 3: {acc:.3f}\")\n",
    "\n",
    "acc = evaluate_function(model, testset, tokenizer, gen_mode = 'sampling')\n",
    "print(f\"Accuracy Tarea 3 - sampling: {acc:.3f}\")\n",
    "\n",
    "acc = evaluate_function(model, testset, tokenizer, gen_mode = 'topk')\n",
    "print(f\"Accuracy Tarea 3 - topk: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c14aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Tarea 3 - beam: 0.783\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_function(model, testset, tokenizer, gen_mode = 'beam')\n",
    "print(f\"Accuracy Tarea 3 - beam: {acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
